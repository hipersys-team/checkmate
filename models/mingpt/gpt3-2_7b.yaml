data_config:
  vocab_size: 50257
  total_tokens: 16385
  block_size: 2048
  train_split: 0.9
  truncate: 0.05
gpt_config:
  n_layer: 32
  n_head: 32
  n_embd: 2560
trainer_config:
  max_epochs: 1
  batch_size: 2
  data_loader_workers: 4
  grad_norm_clip: 1.0
  snapshot_path: gpt3_7b_snapshot
  save_every: 5
  use_amp: True
optimizer_config:
  weight_decay: 0.1
  learning_rate: 0.0003

hydra:
  run:
    dir: ./
